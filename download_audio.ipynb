{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0e0a51-24a4-4e31-b46e-7f97b76d7651",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install datasets \n",
    "! pip install huggingface_hub\n",
    "! pip install transformers\n",
    "! pip install evaluate\n",
    "! pip install jiwer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e99831d-adba-4465-8c67-e008474b43bc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759fdde8-7247-40a2-bd6e-36d6dc18f8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the speaker-specific dataset from Hugging Face\n",
    "dataset = load_dataset(\"ganga4364/Dilgo-Khyentse-Rinpoche-dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b9fbdf-d69e-4552-9b97-178366e68b0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"ganga4364/Dilgo-Khyentse-Rinpoche-dataset\")\n",
    "\n",
    "# Convert train, validation, and test splits to DataFrames\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "validation_df = dataset[\"validation\"].to_pandas()\n",
    "\n",
    "# Add a column to identify the split\n",
    "train_df[\"split\"] = \"train\"\n",
    "validation_df[\"split\"] = \"validation\"\n",
    "\n",
    "# Concatenate all splits into a single DataFrame\n",
    "combined_df = pd.concat([train_df, validation_df], ignore_index=True)\n",
    "\n",
    "# Print the shape and head of the combined DataFrame\n",
    "print(\"Combined DataFrame shape:\", combined_df.shape)\n",
    "print(combined_df.head())\n",
    "\n",
    "# Save to a CSV file if needed\n",
    "combined_df.to_csv(\"combined_dataset.csv\", index=False)\n",
    "print(\"Combined DataFrame saved to 'combined_dataset.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5665eb19-7ba5-4726-82e6-f432d7186041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import requests\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='failed_downloads.log', level=logging.ERROR, format='%(asctime)s - %(message)s')\n",
    "\n",
    "# Function to download audio file\n",
    "def download_audio(url, file_name, save_path):\n",
    "    # Full path where the audio will be saved\n",
    "    \n",
    "    # Skip download if file already exists\n",
    "    if os.path.exists(save_path):\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Download the file from the URL and save it to the specified path\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()  # Check for HTTP errors\n",
    "        with open(save_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Log the error and file name if the download fails\n",
    "        logging.error(f\"Failed to download {file_name}: {e}\")\n",
    "\n",
    "\n",
    "# Function to download the audio file and perform inference\n",
    "def process_row(row):\n",
    "    url = row['url']\n",
    "    file_name = os.path.basename(url)\n",
    "    \n",
    "    # Create the save path for the temporary audio file\n",
    "    save_path = f\"/data/volume/wav_16k/{file_name}\"\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    \n",
    "    # Function to download the audio file\n",
    "    download_audio(url, file_name, save_path)\n",
    "    \n",
    "    return row\n",
    "\n",
    "# Function to process the DataFrame using Pool\n",
    "def process_dataframe(df):\n",
    "    # Number of processes to run, set to the number of available CPU cores or adjust as needed\n",
    "    num_workers = min(cpu_count(), 5)  # Adjust based on your system capabilities\n",
    "\n",
    "    # Use Pool to process rows in parallel\n",
    "    with Pool(processes=num_workers) as pool:\n",
    "        rows = list(tqdm(pool.imap(process_row, [row for _, row in df.iterrows()]), total=len(df)))\n",
    "\n",
    "    # Convert the processed rows back into a DataFrame\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2faacd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"combined_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19155137-6efb-473c-bcf7-1b8322b5c57b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a26f9f6-dd84-4eab-a6cd-00f3eab3df40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_df = process_dataframe(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-base",
   "language": "python",
   "name": "jupyter-base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
